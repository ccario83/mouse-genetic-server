#!/usr/bin/python
#===============================================================================
# Programmer:	Clinton Cario
# Purpose:	This is a wrapper class for the UCLA EMMA/EMMAX functions
#
# Input:	1) See the BerndtEmma documentation or read the internal documentation
# Output:	1) If everything runs sucessfully, either an emma_results.txt or emmax_results.txt file is produced
#
# Modification History:
#  2012 01 31 --    Moved to new versioning system
#  2012 01 31 --    Increased emmax digit precision to 40
#  2012 02 20 --    Depreciated rpy2 due to R version package conflicts with stringr
#  2012 03 06 --    Added hyperlink for strain list when invalid strain names are detected
#  2012 03 07 --    Fixed bug failing to report an error to the user if  invalid phenotype file is selected
#  2012 03 21 --    Changed generate_genotype_files paths to mirror development environ (RAW/SNP/rawfile.tab structure) Now saves to snp_database_dir if no outdir is specified
#  2012 03 22 --    Added support for 12M SNP set
#  2012 04 02 --    Fixed bug with 12M emma/x genotype file encoding
#  2012 04 02 --    Added support for 8M SNP set
#  2012 04 06 --    Added support for the 7.9M CGD SNP set
#  2012 04 06 --    Modified paths to reflect new SNP directory structure
#  2012 04 11 --    Moved Genotype file checks of run() into emma type loop (so the other algorithm genotype file is not required)
#  2012 04 11 --    Added try clause to os.symlink to allow for 'file exists' exception to be ignored. (allows geno.indir to == outdir; useful for debug folder)
#  2012 04 11 --    Added tarfile compression support for final result compression
#  2012 04 17 --    Added support for gemma
#  2012 04 17 --    Fixed bug that appended snp_set to geno.indir each time run() was called
#  2012 04 25 --    Changed just_parse option in gemma to only parse for 65M
#  2012 07 31 --    Added support to run from the command line with a config file
#  2012 08 30 --    Added redis support for logging
#  2012 08 30 --    Removed BEerror, replaced with write_error and sys.exit(1)
#  2012 11 28 --    Modified write_error to also echo to command line for easier debugging.
#  2013 04 08 --    Redis key now passed as an argument in the configuration file
#===============================================================================

import sys              # for various system functions
import os               # To list files in directories
import csv              # For file output
from decimal import *   # For the progress bar
import subprocess       # To call the emma or emmax scripts
import shutil           # To be able to move emma-kin kinship matricies
import tarfile          # To compress final results
import redis            # To communicate back to ruby on rails
#import rpy2.robjects as robjects    # To run R code (DEPRECIATED due to R version conflict with stringr)
# Set decimal precision to 6
getcontext().prec = 6


class EmmaRunner(object):
    
    # FOR SEVER:
    snp_strain_names = None
    official_name_map = None
    snp_database_dir = '/raid/Genotype Data/'
    emma_code_dir = '/raid/WWW/ror_website/lib/EMMA/'
    emmax_code_dir = '/raid/WWW/ror_website/lib/EMMA/'
    gemma_code_dir = '/raid/WWW/ror_website/lib/EMMA/'
    strain_names_dir = '/raid/WWW/ror_website/lib/EMMA/'
    official_names_dir = '/raid/WWW/ror_website/lib/EMMA/'

    # FOR DEVELOPMENT
    #snp_strain_names = None
    #official_name_map = None
    #snp_database_dir = '/home/clinto/Projects/SNPs/'
    #emma_code_dir = '/home/clinto/Projects/EMMA/Development/'
    #emmax_code_dir = '/home/clinto/Projects/EMMA/Development/'
    #strain_names_dir = '/home/clinto/Projects/EMMA/Development/'
    #official_names_dir = '/home/clinto/Projects/EMMA/Development/'
    
    def __init__(self, ):
        '''
            Properties:
                raw_phenos:             the phenotype information as read from the phenotype file
                processed_phenotypes:   error checked and processed phenotype information 
                phenotype:              the 4th column header of the phenotype file that corresponds to the phenotype name
                pheno_strains:          the strain names found in the phenotype file
                geno_strains:           the official versions of strain names from the selected genotype file, in order relative to snp_strain_names[SNP set]. This list is regenerated by every function that uses it 
                verbose:                whether or not to be verbose in output
                _phenos_were_processed: Conditional on if process_phenotypes was successfully run
                _genos_were_processed:  Conditional on if generate_genotype_files was sucessfully run
                _chosen_snp_set:        Which snp set the phenotypes were processed for
        '''
        self.raw_phenos = None
        self.processed_phenotypes = None
        self.phenotype = None
        self.pheno_strains = None
        self.geno_strains = None
        self.verbose = True
        self._phenos_were_processed = False
        self._genos_were_processed = False
        self._chosen_snp_set = None
        self._log_file = None
        self._error_file = None
        self._redis_log = None
        self._redis_error = None
        self._redis_channel = None
        EmmaRunner.snp_strain_names = self._load_snp_strain_names(EmmaRunner.strain_names_dir+'snp_dataset_strain_names.txt')
        EmmaRunner.official_name_map = self._load_official_name_map(EmmaRunner.official_names_dir+'official_names.txt')

    def set_log_file(self, infile):
        self._log_file = infile
    
    def set_error_file(self, infile):
        self._error_file = infile

    def set_redis_log(self, key):
        if self._redis_channel == None:
            self._redis_channel = redis.StrictRedis(host='localhost',port=6379,db=0)
        self._redis_log = "%s:progress:log" % key

    def set_redis_error(self, key):
        if self._redis_channel == None:
            self._redis_channel = redis.StrictRedis(host='localhost',port=6379,db=0)
        self._redis_error = "%s:error:log" % key

    def write_log(self, entry):
        try:
            if not self._log_file is None:
                log_ofh = open(self._log_file, 'a')
                log_ofh.write(entry+'\n')
                log_ofh.close()
            if not self._redis_log is None:
                self._redis_channel.sadd(self._redis_log, entry)
            if self._log_file is None and self._redis_log is None:
                print entry
        except:
            print "Error writing log entry for BerndtEmma"
            sys.exit(1)
    
    def write_error(self, entry):
        try:
            if not self._error_file is None:
                error_ofh = open(self._error_file, 'a')
                error_ofh.write(entry+'\n')
                error_ofh.close()
            if not self._redis_error is None:
                self._redis_channel.sadd(self._redis_error, entry)
                print entry
            if self._error_file is None and self._redis_error is None:
                print entry
        except:
            print "Error writing error entry for BerndtEmma"
            sys.exit(1)
    
    def _load_snp_strain_names(self, infile):
        '''
            Function to load and the strain names of the snp datasets
            
            Arguments:
                infile: A file containing a header for each SNP genotype set (132K, 4M, 65M, 12M, etc...) and a list of strain spellings (column-wise)
            
            Returns:
                snp_strain_names now contains strain names for ALL snp sets
        '''
        try:        
            fh = open(infile, 'rU')
            dr = csv.DictReader(fh, delimiter='\t')
        except:
            self.write_error("Error loading the snp dataset strain name file")
            "Error loading the snp dataset strain name file"
            sys.exit(1)
        header = dr.fieldnames
        strains = {}
        strains = dict([ (item, []) for item in header ])
        # line = dr.next()
        for line in dr:
            for snp_set, strain in line.items():
                if strain:
                    strains[snp_set].append(strain)
        return strains
    
    
    def _load_official_name_map(self, infile):
        '''
            Function to load the official name list into a dict mapping bad name to new name
            
            Arguments:
                infile: A file containing 3 columns with headers 'source', 'exception', and 'official' where row entries correspond to a unofficial => official name mapping (source is where the unofficial name is found, or 'official')  
            
            Returns:
                a dict mapping 'exception's to 'official' names  
                name_map[exception] => {'official':, 'source':} (eg name_map('KK/HLJ') => {'official':'KK/HIJ', source:'clinto74'}
                'official' names are also mapped back to themselves so that correctly spelled names can also be looked up without error
        '''
        name_map = None
        try:        
            fh = open(infile, 'rU')
            dr = csv.DictReader(fh, delimiter='\t')
            # Name map: name_map[exception] => {'official':, 'source':} (eg name_map('KK/HLJ') => {'official':'KK/HIJ', source:'clinto74'})
            name_map = dict([ (line['exception'],{'official':line['official'], 'source':line['source']}) for line in dr ])
        except:
            self.write_error("Error loading the official strain name")
            sys.exit(1)
            
        # === This next bit of code verifies the intregity of the official list ===
        official_names = [ entry['official'] for entry in name_map.values() if entry['source']=='official' ]
        official_column = [ entry['official'] for entry in name_map.values() ]
        #  Do a check to make sure the official names map back to themselves
        for name in official_names:
            if name_map[name]['official'] != name:
                self.write_error("At least one official name isn't properly corrected (ie. it doesn't map to itself). Please check that all names in the official column are correct.")
                sys.exit(1)
        
        # Verify that the official list only has unique entries
        if not len(official_names) == len(self._find_uniq(official_names)):
            self.write_error("There are multiple official names for at least one name")
            sys.exit(1)
            
        # Verify that of every official mapping can be remapped
        for name in official_column:
            try:            
                name_map[name]['official']
            except:
                self.write_error("At least one official name mapping does not match an official name")
                sys.exit(1)
        
        return name_map
    
    
    def _lookup_official_names(self, unofficial_list):
        '''
            Function to lookup the official names given an unofficial_list
            
            Arguments:
                unofficial_list: A single name or list of names to lookup
            
            Returns:
                A single name or list of official names. Will be exact same size and correspond to unofficial_list, or an exception occurs
        '''
        
        # Determine if a list was sent or just a single name. In the case of a single name, convert it to a list and set the singleton flag
        singleton_flag = False
        if not isinstance(unofficial_list, list):
            unofficial_list = [unofficial_list]
            singleton_flag = True
        
        # For each unofficial name in the list, attempt to look up the official name, and warn which names aren't found
        good_names = []
        error_flag = False
        for name in unofficial_list:
            try:
                good_names.append(EmmaRunner.official_name_map[name]['official'])
            except:
                self.write_error("Unknown (strain) name encountered: " + name)
                error_flag = True
        
        # If any unknown names were encountered, raise an exception
        if error_flag:
            self.write_error("Please use only strain names found on the <a href='http://www.berndtlab.pitt.edu/media/strain_names.xls'>official list</a> and resubmit your job")
            sys.exit(1)
        
        # If a single name was sent, also return just a single name, otherwise return a list
        if singleton_flag:
            return good_names[0]
        else:
            return good_names
    
    
    def load_phenotypes(self, infile):
        ''' 
            Function load and verify the phenotype file
            
            Arguments:
                infile: The file to open. Should be in UCLA EMMA format with only one phenotype column. Columns are: 'Strain', 'Animal_Id','Sex' and one phenotype identifier
                Animal Id's should be unique
                Sex should be Male, Female, or NA if sex doesn't matter (case-insensitive)
                Phenotype values should be numbers
                Can have multiple animals per strain; Phenotypes of animals from the same strain are averaged together
            
            Returns:
                self.raw_phenos now contains raw phenotype information mapping (a list of dicts mapping column header to value).
                [ {'Strain':'BALB/CJ', 'Animal_Id':'7', 'Sex':'Female', 'CLSM34_SM_ln':2.432}, .... ]
        '''
        try:
            fh = open(infile, 'rU')
            dr = csv.DictReader(fh, delimiter='\t')
        except:
            self.write_error("There was a problem reading your phenotype file: '" + infile + "', please see the example and resubmit!")
            sys.exit(1)
        try:
            header = dr.fieldnames
        except:
            self.write_error("There was an error with the phenotype header line, please check it and resubmit!")
            sys.exit(1)
        # Check that the header looks ok
        if (['Strain', 'Animal_Id', 'Sex'] != header[0:3]) or (len(header)!=4):
            self.write_error("Expecting 'Strain', 'Animal_Id', 'Sex', and a phenotype name for column headers")
            sys.exit(1)
        # Get the phenotype name from 4th column and read the table
        self.phenotype = header[3]
        # Load the data into the raw phenotype object
        self.raw_phenos = [ line for line in dr ]
        # And store the phenotype strain names (ordered)
        self.pheno_strains = self._get_column(self.raw_phenos, 'Strain')
        # Check that the strains are all valid
        # NOTE: THIS CAN'T BE DETERMINED UNTIL THE GENOTYPE FILE IS KNOWN, CHECK WHEN THIS IS SET IN process_phenotypes
        # Check that the Animal_Id is unique
        if not self._is_uniq(self._get_column(self.raw_phenos, 'Animal_Id')):
            self.write_error("Expecting unique Animal Id's")
            sys.exit(1)
        # Check that the sex is classified as either MALE, FEMALE, or NA (case insensitive)
        if not self._is_subset(self._get_column(self.raw_phenos, 'Sex'), ['Male','Female','NA'], case_sensitive=False):
            #print self._find_set_difference(self._get_column(self.raw_phenos, 'Sex'), ['Male','Female','NA'])
            self.write_error("Expecting 'Male', 'Female', or 'NA' for sex")
            sys.exit(1)
        # Check that the phenotype values are all float coercible      
        try:
            [ float(val) for val in self._get_column(self.raw_phenos, header[3]) ]
        except:
            self.write_error("Phenotype values should float coercible (ie. a number)")
            sys.exit(1)
        if self.verbose:
            self.write_log("reading-phenotypes")
    
    
    def process_phenotypes(self, snp_set, sex_subset='NA'):
        ''' 
            Function to parse the phenotype files, filter by sex, and average multiple animal values. 
            
            Arguments:
                snp_set:    132K, 4M, 65M, 12M, etc... -- needed to pull out the proper strain information 
                sex_subset: 'Male', 'Female', or 'NA' if sex doesn't matter (default)
            
            Returns:
                self.processed_phenotypes now contains the processed phenotype information for the selected SNP set (similar structure as self.raw_phenotypes)
                self.geno_strains now contains a list of official names corresponding to columns of the SNP data output file
                self.pheno_strains now contains a list of phenotype's strain names that are also found in the SNP data output file
        '''
        # Get a list of official strains names for just this snp_set
        try:
            self.geno_strains = self._lookup_official_names(EmmaRunner.snp_strain_names[snp_set])
        except:
            self.write_error("The requested SNP dataset does not have a valid strain list (or it was typed incorrectly)")
            sys.exit(1)
        # Verify that the correct subset is specified
        if not self._is_subset([sex_subset], ['Male','Female','NA'], case_sensitive=False):
            #print "Invalid sex specification(s):"
            #print self._find_set_difference(sex_subset, ['Male','Female','NA'])
            self.write_error("To subset by sex, please specify either Male, Female, or NA (to ignore sex/include both)")
            sys.exit(1)
        # Make sure that snp_set is valid
        if not snp_set in EmmaRunner.snp_strain_names.keys():
            self.write_error("Please choose a valid SNP set for snp_set")
            sys.exit(1)
        
        # NOTE: phenotype strains are checked against the genotype strain names after sex filtering and multiple animal averaging occurs
        
        # Filter out by sex if requested
        if not sex_subset == 'NA':
            self.processed_phenotypes = [ entry for entry in self.raw_phenos if entry['Sex'].upper()==sex_subset.upper() ]
        else:
            self.processed_phenotypes = self.raw_phenos
        # Update the phenotype strain list (ordered)
        self.pheno_strains = self._get_column(self.processed_phenotypes, 'Strain')
        
        # Take the mean of duplicated strains if more than one animal per strain is found
        if not self._is_uniq(self.pheno_strains):
            animal_id = 1
            meaned_phenos = []
            # Get the indicies of each strain, and mean the values
            uniq_strain_list = self._find_uniq(self.pheno_strains)
            for this_strain in uniq_strain_list:
                values = [ float(entry[self.phenotype]) for entry in self.processed_phenotypes if entry['Strain'] == this_strain ]
		mean_value = self.mean(values)
                meaned_phenos.append({ 'Strain':this_strain, 'Animal_Id':'G' + str(animal_id), 'Sex':sex_subset, self.phenotype:mean_value })
                animal_id = animal_id + 1
            self.processed_phenotypes = meaned_phenos
        # Update the phenotype strain list (ordered)
        self.pheno_strains = self._get_column(self.processed_phenotypes, 'Strain')
        
        # Make all strain names official, and remove those not also present in the genotype file
        geno_matched_phenos = []        
        for pheno in self.processed_phenotypes:
            pheno['Strain'] = self._lookup_official_names(pheno['Strain'])
            if pheno['Strain'] in self.geno_strains:
                geno_matched_phenos.append(pheno)
        
        # Update the data
        self.processed_phenotypes = geno_matched_phenos
        self.pheno_strains = self._get_column(self.processed_phenotypes, 'Strain')
        self._phenos_were_processed = True
        self._chosen_snp_set = snp_set
        if self.verbose:
            self.write_log("processing-phenotypes")
    
    
    def generate_genotype_files(self, snp_set, outdir=None):
        ''' 
            Function to parse the genotype files for both EMMA and EMMAX (no time difference to do both vs. just one). 
            
            Arguments:
                snp_set:            132K, 4M, 65M, 12M, etc... -- needed to know how to parse the raw SNP files
                
            Returns:
                snpID is reformed to be '[ID]-[chr]-[pos]' for parsing of emmax output.
                [snp_set]_for_emma.tab - row labels are snpIDs, column labels are Strain names. '1' for homozygous relative to reference allele, .5 for heterozygous, and 0 for homozygous alternative allele, NA for unknown
                [snp_set]_for_emmax.tped - tped format, no headers. Each row is: [chr]  [snpID]    0   [pos] {strain: [ allele1 genotype ('2' for ref allele, '1' for alternative allele, '0' for unknown), allele2 genotype]} 
                
            NOTE:
                The 65M dataset requires a bit of preprocessing:
                 1) Download the file: ftp://ftp-mouse.sanger.ac.uk/current_snps/20111102-snps-all.vcf.gz 
                    and the corresponding annotation: ftp://ftp-mouse.sanger.ac.uk/current_snps/20111102-snps-all.annotated.vcf.gz
                 2) Install tabix from here: http://packages.ubuntu.com/oneiric/amd64/tabix/download
                 3) Install vcftools from here: http://vcftools.sourceforge.net/
                 4) Either download the tabix file, or generate it with tabix -p vcf file.vcf.gz
                 5) Convert the file to the newer format if needed: zcat file.vcf.gz | vcf-convert -r reference.fa > file_v4.vcf
                 6) Convert to a tab delimited file: zcat file.vcf.gz | vcf-to-tab > out.tab
        '''
        # Update the SNP database location to the proper SNP directory
        snp_database_dir = EmmaRunner.snp_database_dir + snp_set + '/'
        # Make sure an output directory was specified
        if not outdir:
            outdir = snp_database_dir
            #self.write_error("You must specify where to save your genotype files with outdir when calling generate_genotype_files.")
            #sys.exit(1)
        # Get a list of official strains names for just this snp_set
        try:
            self.geno_strains = self._lookup_official_names(EmmaRunner.snp_strain_names[snp_set])
        except:
            self.write_error("The requested SNP dataset does not have a valid strain list (or it was typed incorrectly)")
            sys.exit(1)
        # Make sure that snp_set is valid
        if not snp_set in EmmaRunner.snp_strain_names.keys():
            self.write_error("Please choose a valid SNP set for snp_set")
            sys.exit(1)
        
        # Attempt to open file handles (file size is in bytes as found with wc --bytes file)
        try:
            geno_ifh   = None
            emma_ofh   = None
            emmaX_ofh  = None
            geno_file_size = 0.0
            if snp_set == "132K":
                geno_ifh = open(snp_database_dir + 'Raw/132K_Merged_Hapmap_WT_Genotypes.tab', 'rU')
                geno_file_size = Decimal('138248993')
                emma_ofh   = open(outdir + '132K_for_emma.tab', 'w') 
                emmaX_ofh  = open(outdir + '132K_for_emmax.tped', 'w')
            elif snp_set == "4M":
                geno_ifh = open(snp_database_dir + 'Raw/4M_mousehapmap_perlegen_imputed_full_HC.tab', 'rU')
                geno_file_size = Decimal('848957502')
                emma_ofh   = open(outdir + '4M_for_emma.tab', 'w') 
                emmaX_ofh  = open(outdir + '4M_for_emmax.tped', 'w')
            elif snp_set == "65M":
                geno_ifh = open(snp_database_dir + '65M_Sanger.tab', 'rU')
                geno_file_size = Decimal('5327025962')
                emma_ofh   = open(outdir + '65M_for_emma.tab', 'w') 
                emmaX_ofh  = open(outdir + '65M_for_emmax.tped', 'w')
            elif snp_set == "12M":
                geno_ifh = open(snp_database_dir + 'Raw/12M_UNC.tab', 'rU')
                geno_file_size = Decimal('2551390379')
                emma_ofh   = open(outdir + '12M_for_emma.tab', 'w') 
                emmaX_ofh  = open(outdir + '12M_for_emmax.tped', 'w')
            elif snp_set == "8M":
                geno_ifh = open(snp_database_dir + 'Raw/8M_mousehapmap_perlegen_imputed_all_AC.tab', 'rU')
                geno_file_size = Decimal('1793011887')
                emma_ofh   = open(outdir + '8M_for_emma.tab', 'w') 
                emmaX_ofh  = open(outdir + '8M_for_emmax.tped', 'w')
            elif snp_set == "7.9M":
                geno_ifh = open(snp_database_dir + '7.9M_CGD.tab', 'rU')
                geno_file_size = Decimal('1362356315')
                emma_ofh   = open(outdir + '7.9M_for_emma.tab', 'w') 
                emmaX_ofh  = open(outdir + '7.9M_for_emmax.tped', 'w')
            else:
                self.write_error("The requested snp set's genotype file was not found!")
                sys.exit(1)
        except:
            self.write_error("There was an error opening an input or output file in generate_genotype_files.")
            sys.exit(1)
        
        # The reader for the genotype file
        geno_r = csv.reader(geno_ifh, delimiter ='\t')
        # The writer for emma
        emma_w = csv.writer(emma_ofh, delimiter = '\t')
        # The writer for emmax
        emmaX_w = csv.writer(emmaX_ofh, delimiter = '\t')
        
        # Generate the files
        upTick = 0.1
        if snp_set == "132K":
            # Check that the strains in this file are what we are expecting
            header = geno_r.next()[2:]
            if not len(self._find_set_difference(self.geno_strains, self._lookup_official_names(header))) == 0:
                #print header, self.geno_strains
                self.write_error("The genotype file does not appear to have the expected strain names")
                sys.exit(1)
            # Throw away the description line
            geno_r.next()
            # Write the strains as headers to the emma file
            emma_w.writerow(self.geno_strains)
            
            if self.verbose:
                print "Generating 132 thousand SNP genotype files for emma and emmaX ... "
            # parse each line in the genotype file
            for line in geno_r:
                pcnt = Decimal(geno_ifh.tell())/geno_file_size*100
                if (float(pcnt) > upTick):
                    upTick = upTick + 0.1
                    #print("%.2f%%   \r" % float(pcnt))
                    
                # Get the reference and strain alleles
                snpID             = line[0]
                refAllele         = line[2].split(":")[0]
                otherAlleles      = line[2:]
                # Also get the chromosome and position for emmax
                junk, chromo, pos = line[0].split("-")
                # Update the snpid to include chromosome and position
                snpID = "/".join([snpID, chromo, pos])
                # To store the current output line for emma    
                outline           = [snpID]
                # To store the current output line for emmax
                outlineX          = [ chromo, snpID, 0, pos ]
                # Encode it numerically
                # allele = otherAlleles[0]
                for allele in otherAlleles:
                    allele = allele.split(":")[0]
                    allele = allele.upper()
                    alleleX = 0
                    if (allele == "NOCALL"):
                        allele = "NA"
                        alleleX = 0
                    elif (allele.upper()==refAllele):
                        allele = 1
                        alleleX = 1
                    else:
                        allele = 0
                        alleleX = 2
                    outline.append(allele)
                    outlineX.extend([ alleleX, alleleX ])
                # Write the output
                emma_w.writerow(outline)
                emmaX_w.writerow(outlineX)
        
        elif snp_set == "4M":
            # Check that the strains in this file are what we are expecting
            header = geno_r.next()[4:]
            if not len(self._find_set_difference(self.geno_strains, self._lookup_official_names(header))) == 0:
                #print header, self.geno_strains
                self.write_error("The genotype file does not appear to have the expected strain names")
                sys.exit(1)
            # Write the strains as headers to the emma file
            emma_w.writerow(self.geno_strains)
            
            if self.verbose:
                print "Generating 4 million SNP genotype files for emma and emmaX ... "
            # parse each line in the genotype file            
            for line in geno_r:
                pcnt = Decimal(geno_ifh.tell())/geno_file_size*100
                if (float(pcnt) > upTick):
                    upTick = upTick + 0.1
                    #print("%.2f%%   \r" % float(pcnt))
                    
                # Get the reference and strain alleles
                snpID        = line[0]
                refAllele    = line[3].split("/")[0]
                otherAlleles = line[4:]
                # Also get the chromosome and position for emmax
                chromo       = line[1]
                pos          = line[2]
                # Update the snpid to include chromosome and position
                snpID = "/".join([snpID, chromo, pos])
                # To store the current output line for emma
                outline           = [snpID]
                # To store the current output line for emmax
                outlineX          = [ chromo, snpID, 0, pos ]
                # Encode it numerically
                # allele = otherAlleles[0]
                for allele in otherAlleles:
                    allele = allele.upper()
                    alleleX = 0
                    if (allele == "N"):
                        allele = "NA"
                        alleleX = 0
                    elif (allele.upper()==refAllele):
                        allele = 1
                        alleleX = 1
                    else:
                        allele = 0
                        alleleX = 2
                    outline.append(allele)
                    outlineX.extend([ alleleX, alleleX ])
                # Write the output
                emma_w.writerow(outline)
                emmaX_w.writerow(outlineX)
        
        elif snp_set == "65M":
            # Check that the strains in this file are what we are expecting
            header = geno_r.next()[3:]
            if not len(self._find_set_difference(self.geno_strains, self._lookup_official_names(header))) == 0:
                #print header, self.geno_strains
                self.write_error("The genotype file does not appear to have the expected strain names")
                sys.exit(1)
            # Write the strains as headers to the emma file
            emma_w.writerow(self.geno_strains)
            
            if self.verbose:
                print "Generating 65 million SNP genotype files for emma and emmaX ... "
            # parse each line in the genotype file
            for line in geno_r:
                pcnt = Decimal(geno_ifh.tell())/geno_file_size*100
                if (float(pcnt) > upTick):
                    upTick = upTick + 0.1
                    #print("%.2f%%   \r" % float(pcnt))
                    
                # Get the reference and strain alleles
                refAllele    = line[2]
                otherAlleles = line[3:]
                # Also get the chromosome and position for emmax
                chromo       = line[0]
                pos          = line[1]
                snpID        = "/".join([ "-", chromo, pos])
                # To store the current output line for emma    
                outline           = [snpID]
                # To store the current output line for emmax
                outlineX          = [ chromo, snpID, 0, pos ]
                # Encode it numerically
                # allele = otherAlleles[0]
                for allele in otherAlleles:
                    allele1, allele2 = allele.upper().split("/")
                      
                    # Determine how to code the first allele (if not found, will be 0)
                    if (allele1 == "."):
                        allele1 = 0
                    elif (allele1 == refAllele):
                        allele1 = 1
                    else:
                        allele1 = 2
            
                    if (allele2 == "."):
                        allele2 = 0
                    elif (allele1 == refAllele):
                        allele2 = 1
                    else:
                        allele2 = 2
                    
                    allele = ((allele1==refAllele)+(allele2==refAllele))*.5
                    outline.append(allele)
                    outlineX.extend([ allele1, allele2 ])
                # Write the output
                emma_w.writerow(outline)
                emmaX_w.writerow(outlineX)
                
        elif snp_set == "12M":
            # Check that the strains in this file are what we are expecting
            header = geno_r.next()[2:]
            if not len(self._find_set_difference(self.geno_strains, self._lookup_official_names(header))) == 0:
                #print header, self.geno_strains
                self.write_error("The genotype file does not appear to have the expected strain names")
                sys.exit(1)
            # Write the strains as headers to the emma file
            emma_w.writerow(self.geno_strains)
            
            if self.verbose:
                print "Generating 12 million SNP genotype files for emma and emmaX ... "
            # parse each line in the genotype file
            for line in geno_r:
                pcnt = Decimal(geno_ifh.tell())/geno_file_size*100
                if (float(pcnt) > upTick):
                    upTick = upTick + 0.1
                    #print("%.2f%%   \r" % float(pcnt))
                    
                # Get the reference and strain alleles
                refAllele    = line[7]
                otherAlleles = line[2:]
                # Also get the chromosome and position for emmax
                chromo       = line[0]
                pos          = line[1]
                snpID        = "/".join([ "-", chromo, pos])
                # To store the current output line for emma    
                outline           = [snpID]
                # To store the current output line for emmax
                outlineX          = [ chromo, snpID, 0, pos ]
                # Encode it numerically
                # allele = otherAlleles[0]
                for allele in otherAlleles:
                    if allele == 'H':           # Het for reference Allele
                        emma_allele = 0.5
                        emmax_allele1 = 1
                        emmax_allele2 = 2
                    elif allele == refAllele:   # Homo for reference allele
                        emma_allele = 1
                        emmax_allele1 = 1
                        emmax_allele2 = 1
                    elif allele == 'N':         # Unknown alleles
                        emma_allele = "NA"
                        emmax_allele1 = 0
                        emmax_allele2 = 0
                    else:
                        emma_allele = 0
                        emmax_allele1 = 2
                        emmax_allele2 = 2
                        
                    outline.append(emma_allele)
                    outlineX.extend([ emmax_allele1, emmax_allele2 ])
                # Write the output
                emma_w.writerow(outline)
                emmaX_w.writerow(outlineX)
                
                
        elif snp_set == "8M":
            # Check that the strains in this file are what we are expecting
            header = geno_r.next()[4:]
            if not len(self._find_set_difference(self.geno_strains, self._lookup_official_names(header))) == 0:
                #print header, self.geno_strains
                self.write_error("The genotype file does not appear to have the expected strain names")
                sys.exit(1)
            # Write the strains as headers to the emma file
            emma_w.writerow(self.geno_strains)
            
            if self.verbose:
                print "Generating 8 million SNP genotype files for emma and emmaX ... "
            # parse each line in the genotype file            
            for line in geno_r:
                pcnt = Decimal(geno_ifh.tell())/geno_file_size*100
                if (float(pcnt) > upTick):
                    upTick = upTick + 0.1
                    #print("%.2f%%   \r" % float(pcnt))
                    
                # Get the reference and strain alleles
                snpID        = line[0]
                refAllele    = line[3].split("/")[0]
                otherAlleles = line[4:]
                # Also get the chromosome and position for emmax
                chromo       = line[1]
                pos          = line[2]
                # Update the snpid to include chromosome and position
                snpID = "/".join([snpID, chromo, pos])
                # To store the current output line for emma
                outline           = [snpID]
                # To store the current output line for emmax
                outlineX          = [ chromo, snpID, 0, pos ]
                # Encode it numerically
                # allele = otherAlleles[0]
                for allele in otherAlleles:
                    allele = allele.upper()
                    alleleX = 0
                    if (allele == "N"):
                        allele = "NA"
                        alleleX = 0
                    elif (allele.upper()==refAllele):
                        allele = 1
                        alleleX = 1
                    else:
                        allele = 0
                        alleleX = 2
                    outline.append(allele)
                    outlineX.extend([ alleleX, alleleX ])
                # Write the output
                emma_w.writerow(outline)
                emmaX_w.writerow(outlineX)        
            
            
        elif snp_set == "7.9M":
            # Check that the strains in this file are what we are expecting
            header = geno_r.next()[3:]
            if not len(self._find_set_difference(self.geno_strains, self._lookup_official_names(header))) == 0:
                #print header, self.geno_strains
                self.write_error("The genotype file does not appear to have the expected strain names")
                sys.exit(1)
            # Write the strains as headers to the emma file
            emma_w.writerow(self.geno_strains)
            
            if self.verbose:
                print "Generating 7.9 million SNP genotype files for emma and emmaX ... "
            # parse each line in the genotype file            
            for line in geno_r:
                pcnt = Decimal(geno_ifh.tell())/geno_file_size*100
                if (float(pcnt) > upTick):
                    upTick = upTick + 0.1
                    #print("%.2f%%   \r" % float(pcnt))
                    
                # Get the reference and strain alleles
                snpID        = line[0]
                refAllele    = line[18].upper()
                otherAlleles = line[3:]
                # Also get the chromosome and position for emmax
                chromo       = line[1]
                pos          = line[2]
                # Update the snpid to include chromosome and position
                snpID = "/".join([snpID, chromo, pos])
                # To store the current output line for emma
                outline           = [snpID]
                # To store the current output line for emmax
                outlineX          = [ chromo, snpID, 0, pos ]
                # Encode it numerically
                # allele = otherAlleles[0]
                for allele in otherAlleles:
                    allele = allele.upper()
                    alleleX = 0
                    if (allele == "N"):
                        allele = "NA"
                        alleleX = 0
                    elif (allele.upper()==refAllele):
                        allele = 1
                        alleleX = 1
                    else:
                        allele = 0
                        alleleX = 2
                    outline.append(allele)
                    outlineX.extend([ alleleX, alleleX ])
                # Write the output
                emma_w.writerow(outline)
                emmaX_w.writerow(outlineX)
        
        elif snp_set == "1.2M_UNC" or snp_set == "1.2M_NIEHS":
            if self.verbose:
                self.write_error("The 1.2M SNP sets are derived from other emma/emmax SNP input files using shell and awk scripts and are not created with Berndt Emma. Please run these instead... ")
                print "The 1.2M SNP sets are derived from other emma/emmax SNP input files using shell and awk scripts and are not created with Berndt Emma. Please run these instead... "
        
        geno_ifh.close()
        emma_ofh.close()
        emmaX_ofh.close()
        
        # Run the emmax-kinship program
        # NOTE: need to create a dummy tfam file ID ID ID ID 0 NA 
        #if self.verbose:
        #    self.write_log("Generating emmax kinship matrix...")
        #kinship_cmd = EmmaRunner.emmax_code_dir + 'emmax-kin -h -s -d 20 ' + EmmaRunner.snp_database_dir + snp_set + '_for_emmax'
        #subprocess.call(kinship_cmd, shell=True)   
        
        self._genos_were_processed = True
        if self.verbose:
            self.write_log("genotypes-processed")
    
    def generate_phenotype_files(self, outdir=None):
        ''' This function saves the processed phenotype information into a file in the required formats for emma and emmax to outdir'''
        
        # Make sure the phenotype files were processed  
        if (not self._phenos_were_processed) or (not self._chosen_snp_set in EmmaRunner.snp_strain_names.keys()):
            self.write_error("Please process your phenotypes first with process_phenotypes")
            sys.exit(1)
        # Get a list of official strains names for just this snp_set
        try:
            self.geno_strains = self._lookup_official_names(EmmaRunner.snp_strain_names[self._chosen_snp_set])
        except:
            self.write_error("The requested SNP dataset does not have a valid strain list (or it was typed incorrectly)")
            sys.exit(1)
  
        # NOTE, just use shutil to copy emmax tfam file to gemma tfam file, they are exactly the same
        #gemma_tfam_ofh   = open(outdir + self._chosen_snp_set + '_for_gemma.tfam', 'w')
        gemma_fam_ofh    = open(outdir + self._chosen_snp_set + '_for_gemma.fam', 'w')
        emmax_tfam_ofh   = open(outdir + self._chosen_snp_set + '_for_emmax.tfam', 'w')
        emmax_pheno_ofh  = open(outdir + self._chosen_snp_set + '_for_emmax_phenos.tab', 'w')
        emma_pheno_ofh   = open(outdir + self._chosen_snp_set + '_for_emma_phenos.tab', 'w')
            
        gemma_fam_w  = csv.writer(gemma_fam_ofh, delimiter = '\t')    
        emmax_tfam_w  = csv.writer(emmax_tfam_ofh, delimiter = '\t')
        emmax_pheno_w = csv.writer(emmax_pheno_ofh, delimiter = '\t')
        emma_pheno_w  = csv.writer(emma_pheno_ofh, delimiter = '\t')
        # Write the header line for emma phenos        
        emma_pheno_w.writerow(['Strain','Animal_Id','Sex',self.phenotype])
        
        # Remap the processed phenos to a dict mapping strain to pheno
        phenos = dict([ (pheno['Strain'],pheno) for pheno in self.processed_phenotypes ])
        
        # Write the emmax tfam and pheno file and the emma pheno file
        na_animal_ID = 1
        for strain in self.geno_strains:
            try:
                animal_ID = phenos[strain]['Animal_Id']
                sex       = phenos[strain]['Sex']
                value     = phenos[strain][self.phenotype]
                gemma_fam_w.writerow([animal_ID, animal_ID, animal_ID, animal_ID, self._encode_sex(sex), value])
                emmax_tfam_w.writerow([animal_ID, animal_ID, animal_ID, animal_ID, self._encode_sex(sex), value])
                emmax_pheno_w.writerow([animal_ID, animal_ID, value])
                emma_pheno_w.writerow([strain, animal_ID, sex, value])
            except:
                animal_ID = '99'+ str(na_animal_ID)
                na_animal_ID = na_animal_ID + 1
                gemma_fam_w.writerow([animal_ID, animal_ID, animal_ID, animal_ID, 0, -9])
                emmax_tfam_w.writerow([animal_ID, animal_ID, animal_ID, animal_ID, 0, 'NA'])
                emmax_pheno_w.writerow([animal_ID, animal_ID, 'NA'])
        
        gemma_fam_ofh.close()
        emmax_tfam_ofh.close()
        emmax_pheno_ofh.close()
        emma_pheno_ofh.close()
        if self.verbose:
            self.write_log("phenotypes-generated")

    
    def run(self, snp_set=None, emma_type=None, geno_indir=None, phenos_indir=None, outdir=None):
        ''' 
            Function to run either EMMA and EMMAX
            
            Arguments:
                snp_set:            132K, 4M, 65M, 12M, etc...
                emma_type:          'emma' to run emma or 'emmax' to run emmax
                geno_indir:         The location where generate_genotype_files() saved the processed genotype files
                phenos_indir:       The location where generate_phenotype_files() saved the processed phenotype files
                outdir:             Where you want the results to be saved 
                
            Returns:
                A file called 'emma_results' for emma or 'emmax_results.ps' for emmax
                Other run files will be included in the directory, but can be ignored or deleted
                
            NOTE:
                Due to computational requirments you cannot use 'emmax' and '65M' both as arguments
        '''
        
        # If no snp_set was given, attempt to set it to the one used by processed_phenotypes if avaliable
        if not snp_set and self.chosen_snp_set:
            snp_set = self.chosen_snp_set
        elif not snp_set:
            self.write_error("You must specify a snp_set or have run process_phenotypes() with this EmmaRunner object.")
            sys.exit(1)
        # If no geno_indir was given, attempt to set it to snp database directory
        if not geno_indir:
            # Update the SNP database location for this SNP set
            geno_indir = EmmaRunner.snp_database_dir + snp_set + '/'
        self.write_log("processing-genotypes")

        # Make sure directories were specified
        if not snp_set or not emma_type or not phenos_indir or not outdir:
            self.write_error("You must specify at least an emma type ('emma','emmax') and a directory where processed phenotypes were saved with process_phenotypes().")
            sys.exit(1)
        # Make sure the snp_set specification is valid
        if not snp_set in EmmaRunner.snp_strain_names.keys():
            self.write_error("Please choose a valid SNP set for snp_set")
            sys.exit(1)
        # Make sure the emma_type is valid
        if not emma_type in ['emma','emmax', 'gemma']:
            self.write_error("Please specify 'emma' or 'emmax' for the type of emma run (emma_type)")
            sys.exit(1)
        # NOTE: The phenotype and genotype process checks were disabled to allow files processed from other BerntEmma sessions to be run
        # Check that the phenotypes were processed
        #if not self._phenos_were_processed:
        #    self.write_error"Please process phenotypes before running emma(x)")
        # Check that the genotypes were processed
        #if not self._genos_were_processed:
        #    self.write_error"Please process your SNP genotypes before running emma(x)")
        
        
        # FOR EMMA, make sure 65M wasn't selected
        if emma_type == 'emma':
            # Check for a valid genotype/pheontype files in the provided locations
            if not snp_set + '_for_emma.tab' in os.listdir(geno_indir):
                self.write_error("A processed SNP genotype file was not found in the genotype directory (geno_indir) for snp_set. Please run generate_genotype_files() first.")
                sys.exit(1)
            if not snp_set + '_for_emma_phenos.tab' in os.listdir(phenos_indir):
                self.write_error("A processed phenotype file was not found in the phenotype directory (phenos_indir) for snp_set. Please run generate_phenotype_files() first.")
                BEerror("A processed phenotype file was not found in the phenotype directory (phenos_indir) for snp_set. Please run generate_phenotype_files() first.")            
            
            if snp_set == '65M' or snp_set == '12M':
                self.write_error("Using the " + snp_set + " SNP set with emma is not recommended and disabled in this version of EmmaRunner")
                sys.exit(1)
            
            if self.verbose:
                    self.write_log("running-associations")
            job_ifh = open(outdir + 'EMMA_job.Rscript', 'w')
            job_ifh.write('source("'+EmmaRunner.emma_code_dir+'emma.R")\n\n'
            + 'geno.infile = "' + geno_indir + snp_set + '_for_emma.tab'+'"\n' \
            + 'phenos.infile = "' + phenos_indir + snp_set + '_for_emma_phenos.tab"\n' \
            + 'outdir = "' + outdir + '"\n' \
            + 'emma.src = "' + EmmaRunner.emma_code_dir + 'emma_src.R"\n\n' \
            + 'emma(geno.infile, phenos.infile, outdir, emma.src, verbose=FALSE)')
            job_ifh.close()

            cmd = ['Rscript',outdir+'EMMA_job.Rscript']
            #print cmd
            process = subprocess.Popen(cmd)
            self.write_log("post-processing")
            process.wait()

            # Compress the results
            self._compress_files(requested_files = [outdir + 'emma_results.txt'], gz_filename = 'emma_results.tar.gz', requested_location = outdir)
            
        elif emma_type == 'emmax':
            # Check for a valid genotype/phenotype files in the provided locations
            if not snp_set + '_for_emmax_phenos.tab' in os.listdir(phenos_indir):
                self.write_error("A processed phenotype file was not found in the phenotype directory (phenos_indir) for snp_set. Please run generate_phenotype_files() first.")
                sys.exit(1)
            if not snp_set + '_for_emmax.tfam' in os.listdir(phenos_indir):
                self.write_error("A processed phenotype file was not found in the phenotype directory (phenos_indir) for snp_set. Please run generate_phenotype_files() first.")
                sys.exit(1)
            # Create a symlink for emmax in the current directory because paths are not handled properly by emmax
            try:
                os.symlink(EmmaRunner.emmax_code_dir + 'emmax', outdir + 'emmax')
            except OSError, e:
                if e.errno != 17:
                    raise
                
            if snp_set == '65M':
                # NOTE: Kinship Matrix is now expected to be pregenerated (due to emmax-kin output directory limitations) and this is now done by generate_genotype_files()
                # kinship_cmd = EmmaRunner.emmax_code_dir + 'emmax-kin -h -s -d 20 ' + geno_indir + snp_set + '_for_emmax '# + outdir + snp_set + '_emmax_kinship.hIBS.kinf'
                #subprocess.call(kinship_cmd, shell=True)
                # NOTE: It doesn't appear that emmax-kin will allow ouput file location specification. Make a symbolic link to this file in the job directory
                try:
                    os.symlink(geno_indir + snp_set + '_for_emmax.hIBS.kinf', outdir + snp_set + '_for_emmax.hIBS.kinf')
                except OSError, e:
                    if e.errno != 17:
                        raise
                
                # EMMAX is only accepting up to 20M SNPs at a time, so this block of code divides the required genotype files (tped/tfam) for the 65M SNP set into four equal parts of ~17M SNPs
                # Emmax is then called on each part, the results are processed with PAFEX, and then the filtered results are merged into a final filtered parsed result file
                # NOTE: THESE 4 FILE SPLITS CAN BE RUN SIMULTANEOUSLY ON DIFFERENT CPU CORES TO SPEED UP RESULT GENERATION AT SOME POINT 
                
                # These are the part extensions for the genotype files
                part = [ 'aa', 'ab', 'ac', 'ad' ]
                # Check first that the genotype files need to be generated, skip if they already exist
                if not os.path.exists(geno_indir + '65M_for_emmax_partaa'):
                    # Split the tped file into four parts
                    split_cmd = 'split -l 16310910 ' + geno_indir + '65M_for_emmax.tped ' + geno_indir + '65M_for_emmax_part'
                    # Run the split command
                    if self.verbose:
                        pass
                        #self.write_log("Splitting 65M genotype files...")
                    subprocess.call(split_cmd, shell=True)

                # Each genotype split should have a correspondingly named tped file, so copy the tfam file to these names. Also create the symbolic links for the genotype files.
                for idx in range(0,4):
                    try:
                        os.symlink(geno_indir + snp_set + '_for_emmax_part' + part[idx] + '.tped', outdir + snp_set + '_for_emmax_part' + part[idx] + '.tped')
                    except OSError, e:
                        if e.errno != 17:
                            raise
                    copy_cmd = 'cp ' + outdir + '65M_for_emmax.tfam ' + outdir + '65M_for_emmax_part' + part[idx] + '.tfam'
                    subprocess.call(copy_cmd, shell=True)

                #idx = 0
                # Now run the split files with emmax, filter through PAFEX and save individual parsed/filtered result files
                for idx in range(0,4):
                    # Run Emmax
                    if self.verbose:
                        self.write_log("running-associations")
                    emmax_cmd = outdir + 'emmax -d 40 -t ' + outdir + '65M_for_emmax_part' + part[idx] + ' -p ' + phenos_indir + '65M_for_emmax_phenos.tab -k ' + outdir + '65M_for_emmax.hIBS.kinf -o ' + outdir + 'emmax_run'
                    subprocess.call(emmax_cmd, shell=True)
                    pafex_cmd = EmmaRunner.emmax_code_dir + 'PAFEX 150000 .1 0 0 ' + outdir + 'emmax_run.ps ' + outdir + 'emmax_run_'+part[idx]
                    # Run PAFEX
                    if self.verbose:
                        pass
                        #self.write_log("Running Parse And Filter EmmaX (PAFEX)...")
                    subprocess.call(pafex_cmd, shell=True)
                
                self.write_log("post-processing")
                # Create a header and recombine all the split parsed/filtered result files
                if self.verbose:
                        pass
                        #self.write_log("Creating header line and merging results")
                header_cmd = "echo 'rsNum\tchr\tpos\tpVal' > " + outdir + "emmax_results.txt"
                subprocess.call(header_cmd, shell=True)
                join_cmd = 'cat ' + outdir + 'emmax_run_aa ' + outdir + 'emmax_run_ab ' + outdir + 'emmax_run_ac ' + outdir + 'emmax_run_ad >> ' + outdir + 'emmax_results.txt'
                subprocess.call(join_cmd, shell=True)
                
                #NOTE: Binner filter here reduces the number of results so that the MHP tool can plot them (both pre- and post- filtered files are made available to the user)
                bin_cmd = EmmaRunner.emmax_code_dir + 'BINNER 1000 ' + outdir + 'emmax_results.txt ' + outdir + 'emmax_results_binned.txt'
                # Run PAFEX
                if self.verbose:
                    pass
                    #self.write_log("Running BINNER filter...")
                subprocess.call(bin_cmd, shell=True)
                
                # Compress the binned file
                self._compress_files(requested_files = [outdir + 'emmax_results_binned.txt'], gz_filename = 'emmax_results_binned.tar.gz', requested_location = outdir)
    
            else: #(for 132K, 4M and 12M, etc... datasets)
                # NOTE: It doesn't appear that emmax-kin will allow ouput file location specification. Make a symbolic link to this file in the current job directory
                try:                
                    os.symlink(geno_indir + snp_set + '_for_emmax.hIBS.kinf', outdir + snp_set + '_for_emmax.hIBS.kinf')
                except OSError, e:
                    if e.errno != 17:
                        raise                
                # Also link the genotype file to the current job directory
                try:
                    os.symlink(geno_indir + snp_set + '_for_emmax.tped', outdir + snp_set + '_for_emmax.tped')
                except OSError, e:
                    if e.errno != 17:
                        raise
                # NOTE: Kinship Matrix is now expected to be pregenerated (due to emmax-kin output directory limitations) and this is now done by generate_genotype_files()
                # kinship_cmd = EmmaRunner.emmax_code_dir + 'emmax-kin -h -s -d 20 ' + geno_indir + snp_set + '_for_emmax '# + outdir + snp_set + '_emmax_kinship.hIBS.kinf'
                #subprocess.call(kinship_cmd, shell=True)
                emmax_cmd = outdir + 'emmax -d 40 -t ' + outdir + snp_set + '_for_emmax -p ' + phenos_indir + snp_set + '_for_emmax_phenos.tab -k ' + outdir + snp_set + '_for_emmax.hIBS.kinf -o ' + outdir + 'emmax_run'

                # Run Emmax
                if self.verbose:
                    self.write_log("running-associations")
                subprocess.call(emmax_cmd, shell=True)
                
                self.write_log("post-processing")
                # Create the emmax run command and start it
                pafex_cmd = EmmaRunner.emmax_code_dir + 'PAFEX 4000000 .1 0 1 ' + outdir + 'emmax_run.ps ' + outdir + 'emmax_run_aa.ps'
                if self.verbose:
                    pass
                    #self.write_log("Running Parse And Filter EmmaX (PAFEX)...")
                subprocess.call(pafex_cmd, shell=True)
                # Add the header line and call the final file emmax_results.ps
                header_cmd = "echo 'rsNum\tchr\tpos\tpVal' > " + outdir + "emmax_results.txt"
                if self.verbose:
                    pass
                    #self.write_log("Creating header line and merging results")
                subprocess.call(header_cmd, shell=True)
                join_cmd = 'cat ' + outdir + 'emmax_run_aa.ps >> ' + outdir + 'emmax_results.txt'
                subprocess.call(join_cmd, shell=True)

            # Compress the results
            self._compress_files(requested_files = [outdir + 'emmax_results.txt'], gz_filename = 'emmax_results.tar.gz', requested_location = outdir)
        
        elif emma_type == 'gemma':
            # Check for a valid genotype/phenotype files in the provided locations
            if not snp_set + '_for_gemma.fam' in os.listdir(phenos_indir):
                self.write_error("A processed phenotype file was not found in the phenotype directory (phenos_indir) for snp_set. Please run generate_phenotype_files() first.")
                sys.exit(1)
            # Create a symlink for emmax in the current directory because paths are not handled properly by emmax
            try:
                os.symlink(EmmaRunner.gemma_code_dir + 'gemma', outdir + 'gemma')
            except OSError, e:
                if e.errno != 17:
                    raise

            # NOTE: It doesn't appear that emmax-kin will allow ouput file location specification. Make a symbolic link to this file in the current job directory
            try:                
                os.symlink(geno_indir + snp_set + '_for_gemma.sXX.txt', outdir + snp_set + '_for_gemma.sXX.txt')
            except OSError, e:
                if e.errno != 17:
                    raise                
            # Also link the genotype files to the current job directory
            try:
                os.symlink(geno_indir + snp_set + '_for_gemma.bed', outdir + snp_set + '_for_gemma.bed')
                os.symlink(geno_indir + snp_set + '_for_gemma.bim', outdir + snp_set + '_for_gemma.bim')
            except OSError, e:
                if e.errno != 17:
                    raise
            
            # Change the current directory for all shell scripts run
            os.chdir(outdir)
            # Generate the gemma run command
            gemma_cmd = './gemma -bfile ' + snp_set + '_for_gemma -k ' + snp_set + '_for_gemma.sXX.txt -fa 2 -o gemma_results' 

            # Run gemma
            if self.verbose:
                self.write_log("running-associations")
            subprocess.call(gemma_cmd, shell=True)
            
            self.write_log("post-processing")
            if self.verbose:
                pass
                #self.write_log("Running Parse And Filter EmmaX (PAFEX)...")
            # Determine if filtering must be done or if results should just be parsed 
            # NOTE: Gemma creates the output subdirectory... keep all other files in the main job directory
            just_parse = 1 if not snp_set in ['65M' ] else 0
            pafex_cmd = EmmaRunner.gemma_code_dir + 'PAFEX_gemma 4000000 .1 0 ' + str(just_parse) + ' output/gemma_results.assoc.txt ' + 'gemma_results.txt'
            subprocess.call(pafex_cmd, shell=True)
            
            if snp_set in [ '65M' ]:
                #NOTE: Binner filter here reduces the number of results so that the MHP tool can plot them (both pre- and post- filtered files are made available to the user)
                bin_cmd = EmmaRunner.gemma_code_dir + 'BINNER_gemma 1000 gemma_results.txt gemma_results_binned.txt'
                # Run PAFEX
                if self.verbose:
                    pass
                    #self.write_log("Running BINNER filter...")
                subprocess.call(bin_cmd, shell=True)            
                # Compress the binned file
                self._compress_files(requested_files = ['gemma_results_binned.txt'], gz_filename = 'gemma_results_binned.tar.gz', requested_location = outdir)
            
            # Compress the results
            self._compress_files(requested_files = [outdir + 'gemma_results.txt'], gz_filename = 'gemma_results.tar.gz', requested_location = outdir)
        else:
            self.write_error("You somehow managed to specify an illegal emma type even after this was checked for. This should never happen, good work!")
            sys.exit(1)

    
    def _find_uniq(self, inlist):
        ''' Return a list of unique items in a list (order preserving) '''
        uniques = []
        for item in inlist:
            if item not in uniques:
                uniques.append(item)
        return uniques
    
    def _is_uniq(self, inlist):
        ''' Wrapper for the _find_uniq function to determine if a list is unique '''
        return (len(inlist) == len(self._find_uniq(inlist)))
    
    def _get_column(self, dictionary, col_name):
        ''' Collectes a list of dict key values from a list of dicts '''
        return [ entry[col_name] for entry in dictionary ]
    
    def _is_subset(self, possible_subset, set_, case_sensitive=True):
        ''' Determines if possible_subset is a subset of set_ '''
        if not case_sensitive:
            set_ = [ item.upper() if isinstance(item,str) else item for item in set_ ]
            possible_subset = [ item.upper() if isinstance(item,str) else item for item in possible_subset ]
        return len([ item for item in possible_subset if not item in set_ ])==0
        
    def _find_set_difference(self, set1, set2, case_sensitive=True):
        ''' set1 - set2 '''
        if not case_sensitive:
            set1 = [ item.upper() if isinstance(item,str) else item for item in set1 ]
            set2 = [ item.upper() if isinstance(item,str) else item for item in set2 ]
        return [ item for item in set1 if not item in set2 ]
     
    def _encode_sex(self, sex):
        ''' returns 1 for sex of male or m, 2 for sex of female or F, 0 for sex of na or an error otherwise. Case insensitive '''
        if self._is_subset([sex], ['male','m'], case_sensitive=False):
            return 1
        elif self._is_subset([sex], ['female','f'], case_sensitive=False):
            return 2
        elif self._is_subset([sex], ['na'], case_sensitive=False):
            return 0
        else:
            self.write_error("Error while trying to numerically encode sex information. Check that all sexes are 'Male', 'Female', or 'NA'")
            sys.exit(1)
    
    # Modified to just pass for UWF
    def _compress_files(self, requested_files, gz_filename, requested_location):
        '''
        This function takes a list of 'requested_files' in the current job directory and compresses them to a file called 'gz_filename' in the job folder or a 'requested_location'
        '''
        try:
            tf = tarfile.open(requested_location + gz_filename, 'w:gz')
            for requested_file in requested_files:
                tf.add(requested_file, arcname=os.path.split(requested_file)[1])
            tf.close()
        except:
            self.write_error('Error compressing the requested file(s)! Please check the format and try again.')
            sys.exit(1)
    
    @staticmethod
    def mean(values):
        ''' Computes the arithmetic mean of a list of numbers. '''
        return sum(values, 0.0) / len(values)


# Code for this being run as standalone
if __name__ == "__main__":
    print "Running BerndtEmma as standalone script..."
    import subprocess
    import ConfigParser
    import argparse
    import ordereddict
    
    # Add this scripts location to path so executables can be found
    script_dir = os.path.dirname(os.path.realpath(__file__))
    os.chdir(script_dir)
    sys.path.append(script_dir)
    
    # Get the command line arguments
    parser = argparse.ArgumentParser(description='This script abstracts most of the G/EMMA/X functionality')
    parser.add_argument('-c', '--config_file',          action='store',         default='emma.conf',                dest='emma_conf',   help='The location of the emma config file')
    parser.add_argument('-p', '--project_dir',          action='store',         default=None,                       dest='project_dir', help='The location to store the results')
    
    args = parser.parse_args()
    args.project_dir += '/' # Adding trailing slash is good for appending file to path, but doesn't hurt if it is already there
    
    # Get the config file information
    conf = ConfigParser.SafeConfigParser(dict_type=ordereddict.OrderedDict)
    try:
        conf.read(args.emma_conf)
    except:
        print "There was a problem opening your emma config file. Please check the path and try again."
        exit()
    
    def try_and_load(section, var, default):
        try:
            #print "Using the value of [%s] for [%s]"%(conf.get(section, var), var)
            return conf.get(section, var)
        except:
            if not default:
                print "There is a problem with your emma configuration file. Please specifiy '%s' in your config file under '[%s]'." %(var, section)
                exit()
            else:
                #print "Using the default value of [%s] for [%s]"%(default, var)
                return default
    
    snp_set = try_and_load('general', 'snp_set', None)
    pheno_file = try_and_load('general', 'pheno_file', None)
    emma_type =try_and_load('general', 'emma_type', None)
    snp_dir = try_and_load('general', 'snp_dir', '/raid/Genotype Data/')
    redis_key = try_and_load('general', 'redis_key', None)
    
    EmmaRunner.emma_code_dir = try_and_load('general', 'emma_code_dir', '/raid/WWW/ror_website/lib/EMMA/')
    EmmaRunner.emmax_code_dir = try_and_load('general', 'emmax_code_dir', '/raid/WWW/ror_website/lib/EMMA/')
    EmmaRunner.gemma_code_dir = try_and_load('general', 'gemma_code_dir', '/raid/WWW/ror_website/lib/EMMA/')
    EmmaRunner.strain_names_dir = try_and_load('general', 'strain_names_dir', '/raid/WWW/ror_website/lib/EMMA/')
    EmmaRunner.official_names_dir = try_and_load('general', 'official_names_dir', '/raid/WWW/ror_website/lib/EMMA/')
    
    obj = EmmaRunner()
    obj.set_redis_log(redis_key)
    obj.set_redis_error(redis_key)
    obj.load_phenotypes(pheno_file)
    obj.process_phenotypes(snp_set)
    obj.generate_phenotype_files(args.project_dir)
    obj.run(snp_set=snp_set, emma_type=emma_type, geno_indir=snp_dir + "/" + snp_set + "/", phenos_indir=args.project_dir, outdir=args.project_dir)



